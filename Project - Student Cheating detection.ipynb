{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72cc2feb-9ea9-4b3c-82ec-03ba11694cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7510e93f-e7c5-4c24-9c3f-307234dc2828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cmake\n",
      "  Downloading cmake-3.31.4-py3-none-win_amd64.whl.metadata (6.5 kB)\n",
      "Downloading cmake-3.31.4-py3-none-win_amd64.whl (36.5 MB)\n",
      "   ---------------------------------------- 0.0/36.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.8/36.5 MB 14.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 4.7/36.5 MB 13.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 11.0/36.5 MB 19.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 18.1/36.5 MB 23.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 23.3/36.5 MB 23.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 27.8/36.5 MB 23.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 31.5/36.5 MB 22.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  35.7/36.5 MB 22.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 36.5/36.5 MB 21.1 MB/s eta 0:00:00\n",
      "Installing collected packages: cmake\n",
      "Successfully installed cmake-3.31.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff5bced8-ecc4-4411-b6c5-4e8635119499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib\n",
      "  Using cached dlib-19.24.6.tar.gz (3.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): finished with status 'done'\n",
      "  Created wheel for dlib: filename=dlib-19.24.6-cp312-cp312-win_amd64.whl size=2919815 sha256=7f3fd950c81b46563e5202215e4c1120f04d932f45dc8bf571b80b26dab75a10\n",
      "  Stored in directory: c:\\users\\chari\\appdata\\local\\pip\\cache\\wheels\\8d\\16\\b2\\d2df2ea5d9430e80343c7b696e9588e5cc98b0d903d434d768\n",
      "Successfully built dlib\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.24.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "805fae33-914c-4265-9e47-038b9a522c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import json\n",
    "import numpy as np\n",
    "from pymysql.constants import CLIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee8c43-253b-42d3-a64b-55593ad420a0",
   "metadata": {},
   "source": [
    "### Establishing database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b11bb573",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = 'localhost'\n",
    "USER = 'root'\n",
    "PASSWORD = 'Cherry@10082001'\n",
    "CHARSET = 'utf8mb4'\n",
    "DBNAME = 'students'\n",
    "PORT = 3306"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa5d9bb",
   "metadata": {},
   "source": [
    "### Inserting person face into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d794278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDatabase():\n",
    "    \n",
    "    conn = pymysql.connect(\n",
    "        host=HOST,\n",
    "        user=USER,\n",
    "        password=PASSWORD,\n",
    "        port=3306,\n",
    "        cursorclass=pymysql.cursors.DictCursor,\n",
    "        client_flag=CLIENT.MULTI_STATEMENTS\n",
    "    )\n",
    "\n",
    "    sql = \"\\n\".join([\n",
    "    f\"DROP SCHEMA IF EXISTS `{DBNAME}`;\",\n",
    "    f\"CREATE SCHEMA IF NOT EXISTS `{DBNAME}` DEFAULT CHARACTER SET utf8;\",\n",
    "    \"SHOW WARNINGS;\",\n",
    "    f\"USE `{DBNAME}`;\",\n",
    "    f\"DROP TABLE IF EXISTS `{DBNAME}`.`student_face_encodings`;\",\n",
    "    \"SHOW WARNINGS;\",\n",
    "    f\"CREATE TABLE IF NOT EXISTS `{DBNAME}`.`student_face_encodings` (\",\n",
    "    \"    `id` INT NOT NULL AUTO_INCREMENT,\",\n",
    "    \"    `name` NVARCHAR(255) NOT NULL,\",\n",
    "    \"    `faceencoding` TEXT NOT NULL,\",\n",
    "    \"    PRIMARY KEY (`id`)\",\n",
    "    \") ENGINE = InnoDB;\"])\n",
    "\n",
    "    sql = sql.replace(\"\\n\", \"\")\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(sql)\n",
    "            conn.commit()\n",
    "\n",
    "            sql_show = \"SHOW DATABASES\"\n",
    "            cursor.execute(sql_show)\n",
    "            databaseList = cursor.fetchall()\n",
    "            for database in databaseList:\n",
    "                if database['Database'] == DBNAME:\n",
    "                    print(database, 'has been successfully created!')\n",
    "                    break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Database creation failed: {}\".format(e))\n",
    "\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d2de608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Database': 'students'} has been successfully created!\n"
     ]
    }
   ],
   "source": [
    "createDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df2db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertFaceToDatabase(name, encoding):\n",
    "    \n",
    "    conn = pymysql.connect(\n",
    "        host=HOST,\n",
    "        user=USER,\n",
    "        password=PASSWORD,\n",
    "        database=DBNAME,\n",
    "        port=3306,\n",
    "        cursorclass=pymysql.cursors.DictCursor\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            sql = \"INSERT INTO student_face_encodings (name, faceencoding) VALUES ('{}', '{}')\".format(\n",
    "                name, json.dumps(encoding))\n",
    "            cursor.execute(sql)\n",
    "            conn.commit()\n",
    "            print(\"Insertion Success!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print('Insertion Failed!', e)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4765558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchAllStudents():\n",
    "    \n",
    "    conn = pymysql.connect(\n",
    "        host=HOST,\n",
    "        user=USER,\n",
    "        password=PASSWORD,\n",
    "        database=DBNAME,\n",
    "        port=PORT,\n",
    "        cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            sql = \"SELECT name, faceencoding FROM student_face_encodings\"\n",
    "            cursor.execute(sql)\n",
    "            data = cursor.fetchall()\n",
    "            encodings, names = [], []\n",
    "\n",
    "            for i in range(0, len(data)):\n",
    "                names.append(data[i]['name'])\n",
    "                encodings.append(json.loads(data[i]['faceencoding']))\n",
    "\n",
    "            print(\"Fetching Success!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print('Fetching Failed:\\n', e)\n",
    "\n",
    "    conn.close()\n",
    "    return encodings, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "963e77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testInsertion():\n",
    "    data = [-0.06413651,  0.05275547,  0.11465468, -0.06868585, -0.12905313, -0.06219113, -0.08105582, -0.05795766,  0.14002423, -0.14891383, 0.16809663,  0.03969061, -0.24029616,  0.01072336,  0.01820949, 0.20016633, -0.11752109, -0.12041475, -0.0686784,  0.02890174, 0.01413991, -0.00092969, -0.00206049,  0.05478341, -0.07208329, -0.38025042, -0.09110465, -0.03197921, -0.04670967,  0.00347318, -0.1002866,  0.02906058, -0.1258755, -0.06500086,  0.08338613, 0.14355671, -0.08919339, -0.08197339,  0.20867996,  0.01007678, -0.2455171, -0.03276137,  0.07985185,  0.2051305,  0.24185342, 0.0678556,  0.08049953, -0.09811792,  0.18532458, -0.34516171, 0.03625763,  0.09210046,  0.05877451,  0.06729918,  0.12198181, -0.13268434,  0.0351983,  0.13155086, -0.17172278, -0.04020822, 0.00662367, -0.09220872, -0.03645555, -0.07874616, 0.27311197, 0.1041171, -0.13304791, -0.09074535,  0.16285834, -0.18031871, -0.09120225,  0.01239933, -0.09920017, -0.15501264, -0.33115372, -0.01934731,  0.39288402,  0.15537588, -0.15778066,  0.06874227, -0.0653723, -0.03062057,  0.07541025,  0.05756121, -0.02222584, 0.01667677, -0.08238429, -0.01497209,  0.27893612, -0.08270567, 0.05658919,  0.18633389,  0.03200752,  0.08384499,  0.0460855, 0.0695291, -0.09776485, -0.05492003, -0.22801645, -0.05175924, 0.05780323, -0.02099415,  0.0295985,  0.10740275, -0.26527831, 0.09936604, -0.03858019, -0.04595775,  0.04024224, -0.01442718, -0.16451956, -0.08263291,  0.13128407, -0.21504368,  0.14097233, 0.18843487, -0.03240553,  0.11317647,  0.10367718,  0.0171592, -0.02866501, -0.07389878, -0.15731311, -0.09558592,  0.10734915, 0.03525282,  0.05941724,  0.0096033]\n",
    "    \n",
    "    insertFaceToDatabase(name='Cherry', encoding=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384c75b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion Success!\n"
     ]
    }
   ],
   "source": [
    "testInsertion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db465e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testRead():\n",
    "    encodings, names = fetchAllStudents()\n",
    "\n",
    "    print('\\n\\n\\n\\n', type(encodings), encodings, '\\n\\n', names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adff71c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Success!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " <class 'list'> [[-0.06413651, 0.05275547, 0.11465468, -0.06868585, -0.12905313, -0.06219113, -0.08105582, -0.05795766, 0.14002423, -0.14891383, 0.16809663, 0.03969061, -0.24029616, 0.01072336, 0.01820949, 0.20016633, -0.11752109, -0.12041475, -0.0686784, 0.02890174, 0.01413991, -0.00092969, -0.00206049, 0.05478341, -0.07208329, -0.38025042, -0.09110465, -0.03197921, -0.04670967, 0.00347318, -0.1002866, 0.02906058, -0.1258755, -0.06500086, 0.08338613, 0.14355671, -0.08919339, -0.08197339, 0.20867996, 0.01007678, -0.2455171, -0.03276137, 0.07985185, 0.2051305, 0.24185342, 0.0678556, 0.08049953, -0.09811792, 0.18532458, -0.34516171, 0.03625763, 0.09210046, 0.05877451, 0.06729918, 0.12198181, -0.13268434, 0.0351983, 0.13155086, -0.17172278, -0.04020822, 0.00662367, -0.09220872, -0.03645555, -0.07874616, 0.27311197, 0.1041171, -0.13304791, -0.09074535, 0.16285834, -0.18031871, -0.09120225, 0.01239933, -0.09920017, -0.15501264, -0.33115372, -0.01934731, 0.39288402, 0.15537588, -0.15778066, 0.06874227, -0.0653723, -0.03062057, 0.07541025, 0.05756121, -0.02222584, 0.01667677, -0.08238429, -0.01497209, 0.27893612, -0.08270567, 0.05658919, 0.18633389, 0.03200752, 0.08384499, 0.0460855, 0.0695291, -0.09776485, -0.05492003, -0.22801645, -0.05175924, 0.05780323, -0.02099415, 0.0295985, 0.10740275, -0.26527831, 0.09936604, -0.03858019, -0.04595775, 0.04024224, -0.01442718, -0.16451956, -0.08263291, 0.13128407, -0.21504368, 0.14097233, 0.18843487, -0.03240553, 0.11317647, 0.10367718, 0.0171592, -0.02866501, -0.07389878, -0.15731311, -0.09558592, 0.10734915, 0.03525282, 0.05941724, 0.0096033]] \n",
      "\n",
      " ['Cherry']\n"
     ]
    }
   ],
   "source": [
    "testRead()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9029eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8efef97d-06ea-43a7-8dbe-e5a42cb8e2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face_recognition in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from face_recognition) (8.1.7)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from face_recognition) (19.24.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from face_recognition) (2.0.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from face_recognition) (10.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad1b9327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d40a0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertNewPersonWithImage():\n",
    "    image_path = input(\"Please Enter Image Path: \")\n",
    "    name = input(\"Person name: \")\n",
    "    img = ''\n",
    "    encode = []\n",
    "    try:\n",
    "        img = face_recognition.load_image_file(image_path)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        list = encode.tolist()\n",
    "        insertFaceToDatabase(name, list)\n",
    "        print(name, \" Added successfully!\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to load image: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3e8573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please Enter Image Path:  Charitha.jpg\n",
      "Person name:  Charitha\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion Success!\n",
      "Charitha  Added successfully!\n"
     ]
    }
   ],
   "source": [
    "insertNewPersonWithImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00115670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please Enter Image Path:  samantha.jpg\n",
      "Person name:  Samantha\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion Success!\n",
      "Samantha  Added successfully!\n"
     ]
    }
   ],
   "source": [
    "insertNewPersonWithImage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4253f",
   "metadata": {},
   "source": [
    "### Eye Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23b5601f-9ca1-479b-9592-fb141f12af43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python) (2.0.2)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/39.5 MB 4.2 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 3.4/39.5 MB 11.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.6/39.5 MB 14.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.4/39.5 MB 19.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.5/39.5 MB 22.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 25.4/39.5 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 28.3/39.5 MB 20.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 31.5/39.5 MB 19.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 34.1/39.5 MB 19.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 37.2/39.5 MB 18.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.5 MB 18.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 16.8 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9f69060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc930cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36c707bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_on_mask(mask, side):  \n",
    "    points = [shape[i] for i in side]\n",
    "    points = np.array(points, dtype=np.int32)\n",
    "    mask = cv2.fillConvexPoly(mask, points, 255)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4452527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contouring(thresh, mid, img, right=False):\n",
    "    cnts, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    try:\n",
    "        cnt = max(cnts, key=cv2.contourArea)  \n",
    "        M = cv2.moments(cnt)  \n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        if right:\n",
    "            cx += mid  \n",
    "        cv2.circle(img, (cx, cy), 1, (0, 255, 0), 3)  \n",
    "        return cy, cx\n",
    "    except:\n",
    "        pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb4c2032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_eyeballs(y_left, x_left, y_right, x_right, y_center, x_center, img):\n",
    "    try:\n",
    "        diff_x = abs(x_left - x_right) / 4\n",
    "        cv2.putText(img, 'left : ' + str(x_left) + \"  center : \" + str(x_center) + \"  right : \" + str(x_right),\n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 1)\n",
    "        img1 = cv2.imread('cheating.jpeg')\n",
    "        cv2.imshow(\"eyes\", img)\n",
    "        if x_center - diff_x <= x_left:\n",
    "            cv2.putText(img1, \"Dont look left\",(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 3)\n",
    "            cv2.imshow('cheater image looking left', img1)\n",
    "            cv2.waitKey(0)\n",
    "        elif x_center + diff_x >= x_right:\n",
    "            cv2.putText(img1, \"Dont look Right\",(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 3)\n",
    "            cv2.imshow('cheater image looking right', img1)\n",
    "            cv2.waitKey(0)\n",
    "        else:\n",
    "            cv2.destroyWindow('cheater image')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b709873",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open shape_68.dat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m detector \u001b[38;5;241m=\u001b[39m dlib\u001b[38;5;241m.\u001b[39mget_frontal_face_detector()\n\u001b[1;32m----> 2\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mdlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshape_68.dat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m left \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m36\u001b[39m, \u001b[38;5;241m37\u001b[39m, \u001b[38;5;241m38\u001b[39m, \u001b[38;5;241m39\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m41\u001b[39m]  \u001b[38;5;66;03m# keypoint indices for left eye\u001b[39;00m\n\u001b[0;32m      5\u001b[0m right \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m42\u001b[39m, \u001b[38;5;241m43\u001b[39m, \u001b[38;5;241m44\u001b[39m, \u001b[38;5;241m45\u001b[39m, \u001b[38;5;241m46\u001b[39m, \u001b[38;5;241m47\u001b[39m]  \u001b[38;5;66;03m# keypoint indices for right eye\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open shape_68.dat"
     ]
    }
   ],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_68.dat')\n",
    "\n",
    "left = [36, 37, 38, 39, 40, 41]  # keypoint indices for left eye\n",
    "right = [42, 43, 44, 45, 46, 47]  # keypoint indices for right eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee078321",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m ret, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m----> 3\u001b[0m thresh \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n\u001b[0;32m      4\u001b[0m kernel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20\u001b[39m), np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m      5\u001b[0m process_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "ret, img = cap.read()\n",
    "thresh = img.copy()\n",
    "kernel = np.ones((20, 20), np.uint8)\n",
    "process_frame = False\n",
    "while (True):\n",
    "    image2 = np.zeros((1000, 1000, 3), np.uint8)\n",
    "    ret, img = cap.read()\n",
    "    if not process_frame:\n",
    "        process_frame = True\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 1)\n",
    "        for rect in rects:\n",
    "            shape = predictor(gray, rect)  \n",
    "            shape = shape_to_np(shape)  \n",
    "            mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "            mask = eye_on_mask(mask, left)  \n",
    "            mask = eye_on_mask(mask, right)\n",
    "            mask = cv2.dilate(mask, kernel, 5)  \n",
    "            eyes = cv2.bitwise_and(img, img, mask=mask)  \n",
    "            mask = (eyes == [0, 0, 0]).all(axis=2)\n",
    "            eyes[mask] = [255, 255, 255]\n",
    "            mid = (shape[42][0] + shape[39][0]) // 2\n",
    "            eyes_gray = cv2.cvtColor(eyes, cv2.COLOR_BGR2GRAY)\n",
    "            threshold = 67\n",
    "            #threshold = cv2.getTrackbarPos('threshold', 'image')\n",
    "            _, thresh = cv2.threshold(eyes_gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "            thresh = cv2.erode(thresh, None, iterations=2)  # 1\n",
    "            thresh = cv2.dilate(thresh, None, iterations=4)  # 2\n",
    "            thresh = cv2.medianBlur(thresh, 3)  # 3 smoothing the image\n",
    "            thresh = cv2.bitwise_not(thresh)  # to find the eyeballs it need to be white and its background black\n",
    "            eyeLeft = contouring(thresh[:, 0:mid], mid, img)\n",
    "            eyeRight = contouring(thresh[:, mid:], mid, img, True)\n",
    "\n",
    "            try:\n",
    "                compare_eyeballs(shape[36][1], shape[36][0], shape[39][1], shape[39][0], eyeLeft[0], eyeLeft[1],\n",
    "                                 img)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                compare_eyeballs(shape[42][1], shape[42][0], shape[45][1], shape[45][0], eyeRight[0], eyeRight[1],\n",
    "                                 img)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        process_frame = False\n",
    "\n",
    "    cv2.imshow('eyes', img)\n",
    "    #cv2.imshow(\"image\", thresh)\n",
    "    # cv2.destroyWindow('image')\n",
    "    #cv2.destroyWindow('eyePoints')\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c112e2d1",
   "metadata": {},
   "source": [
    "### Face Recognition, Multi-face Detection and Cell-Phone, Textbook detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bb4977-5533-45d9-91f2-350286edcec3",
   "metadata": {},
   "source": [
    "##### Using MobileNet model to detect cell phone and textbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff7ecd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recog(frame, known_faces_encodings: list, names_students: list):\n",
    "\n",
    "        names = []\n",
    "        frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_frame =  np.ascontiguousarray(frame[:, :, ::-1])\n",
    "        encodings = face_recognition.face_encodings(rgb_frame)\n",
    "        for unknown_face_encoding in encodings:\n",
    "            matches = face_recognition.compare_faces(known_faces_encodings, unknown_face_encoding)\n",
    "            name = \"Unknown\"\n",
    "            if True in matches:\n",
    "                match_index = matches.index(True)\n",
    "                name = names_students[match_index]\n",
    "            names.append(name)\n",
    "\n",
    "        if len(names) == 0:\n",
    "            names = [\"No face is visible\"]\n",
    "\n",
    "        return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e51221e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92bb9270-a299-45d0-9bed-bd595591cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"mobilenet_iter_73000.caffemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8fc76a8-642a-4be4-8401-26ab630f1655",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\", \"cellphone\", \"book\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b738d33-fb3d-418a-8d8a-da504db35ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), (127.5, 127.5, 127.5), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    detected_objects = []\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.2:  # Confidence threshold\n",
    "            class_id = int(detections[0, 0, i, 1])\n",
    "            if class_id == 21:  # \"cellphone\" class\n",
    "                detected_objects.append(\"cellphone\")\n",
    "            elif class_id == 22:  # \"book\" class\n",
    "                detected_objects.append(\"book\")\n",
    "    return detected_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f2220ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoCap:\n",
    "\n",
    "    def __init__(self, src=0):\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        self.encodings, self.student_names = fetchAllStudents()\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "        self.names = [\"unknown\"]\n",
    "        self.stopped = False\n",
    "\n",
    "    def get_and_show(self):\n",
    "        no_of_frames = 0\n",
    "        count_multi = 0\n",
    "\n",
    "        while not self.stopped:\n",
    "            if (not self.grabbed) or cv2.waitKey(1) == ord(\"q\"):\n",
    "                self.stop()\n",
    "            else:\n",
    "                (self.grabbed, self.frame) = self.stream.read()\n",
    "                no_of_frames += 1\n",
    "                if no_of_frames % 60 == 0:\n",
    "                    self.names = face_recog(self.frame, self.encodings, self.student_names)\n",
    "                    # using locations instead of encodings because it's faster \n",
    "                    # detect how many faces \n",
    "                    locations = face_recognition.face_locations(self.frame)\n",
    "                    # if more than one then it's group cheating\n",
    "                    if len(locations) > 1:\n",
    "                        count_multi += 1\n",
    "                        print(count_multi)\n",
    "                        img = cv2.imread(\"warning.png\")\n",
    "                        cv2.imshow(\"Multiple faces detected\", img)\n",
    "                    else:\n",
    "                        # Detect faces in the frame\n",
    "                        gray = cv2.cvtColor(self.frame, cv2.COLOR_BGR2GRAY)\n",
    "                        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "                        # Process each detected face\n",
    "                        for (x, y, w, h) in faces:\n",
    "                            roi_gray = gray[y:y + h, x:x + w]                      \n",
    "\n",
    "                # Detect objects (cellphones and books)\n",
    "                detected_objects = detect_objects(self.frame)\n",
    "                for obj in detected_objects:\n",
    "                    if obj == \"cellphone\":\n",
    "                        cv2.putText(self.frame, \"Cellphone Detected!\", (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                        img = cv2.imread(\"warning.png\")\n",
    "                        cv2.imshow(\"Cellphone Detected\", img)\n",
    "                    elif obj == \"book\":\n",
    "                        cv2.putText(self.frame, \"Book Detected!\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                        img = cv2.imread(\"warning.png\")\n",
    "                        cv2.imshow(\"Book Detected\", img)\n",
    "\n",
    "            cv2.putText(self.frame, \" ,\".join(self.names), (10, 40), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 1)\n",
    "            cv2.imshow(\"Live Video\", self.frame)\n",
    "\n",
    "            if count_multi == 3:\n",
    "                print(\"Multiple faces exceeded\")\n",
    "                img = cv2.imread(\"fAILED.jpg\")\n",
    "                cv2.imshow(\"Multiple faces detected\", img)\n",
    "                cv2.waitKey(5000)\n",
    "                self.stop()\n",
    "    def stop(self):\n",
    "        self.stream.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        self.stopped = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cd04937-c57c-4b69-bb69-8e6eb96665a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7ec52ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Success!\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m video \u001b[38;5;241m=\u001b[39m \u001b[43mVideoCap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_and_show\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 53\u001b[0m, in \u001b[0;36mVideoCap.get_and_show\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBook Detected\u001b[39m\u001b[38;5;124m\"\u001b[39m, img)\n\u001b[0;32m     52\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames), (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m40\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_COMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLive Video\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count_multi \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple faces exceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "video = VideoCap().get_and_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2177f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
